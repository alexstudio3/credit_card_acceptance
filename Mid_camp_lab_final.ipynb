{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Borja\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "#general libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import getpass\n",
    "\n",
    "#SQL\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "#plot\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib\n",
    "\n",
    "#from scipy.stats import normaltest\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, PowerTransformer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, cohen_kappa_score, accuracy_score, classification_report\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Gather the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x287273acd08>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connection_string = 'mysql+pymysql://root:' + password + '@localhost/credit_card_classification'\n",
    "engine = create_engine(connection_string)\n",
    "engine.execute(\"USE credit_card_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"\"\"select * from credit_card_classification.credit_card_data_2\"\"\"\n",
    "data = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, 24 rows were dropped by MySQL in the import from the original CSV file to SQL, because some columns were empty (balance & co). We estimate that 24 out of a total of 18000 is not significant.\n",
    "\n",
    "Next, we make a copy of the original dataframe so that we can use it again later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Explore the data, select features to be used for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now set the dataframe index to be the customer_number so that it is not used for the model but, \n",
    "# we don't lose the information in case we need it afterwards.\n",
    "data2.set_index('customer_number', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping features with VIF >5\n",
    "data2 = data2.drop(['bank_accounts_open','credit_cards_held','homes_owned','household_size'], axis=1)\n",
    "\n",
    "#3. dropping in addition to 2. the avg balance\n",
    "#data2 = data2.drop(['bank_accounts_open','credit_cards_held','homes_owned','household_size','balance'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Categorical conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical ordinal\n",
    "# ordinal categoricals have an order and we can substitute the values in just one column, if we respect the order\n",
    "data2['income_level'] = data2['income_level'].map({'Low':0, 'Medium':1, 'High':2})\n",
    "data2['credit_rating'] = data2['credit_rating'].map({'Low':0, 'Medium':1, 'High':2})\n",
    "\n",
    "# We convert the categoricals that have only 2 choices the same way:\n",
    "data2['offer_accepted'] = data2['offer_accepted'].map({'Yes':1, 'No':0})\n",
    "data2['overdraft_protection'] = data2['overdraft_protection'].map({'Yes':1, 'No':0})\n",
    "data2['own_your_home'] = data2['own_your_home'].map({'Yes':1, 'No':0})\n",
    "data2['mailer_type'] = data2['mailer_type'].map({'Postcard':0, 'Letter':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion of the remaining categoricals to numbers via getdummies\n",
    "data3 = data2['reward']\n",
    "data2 = data2.drop('reward', axis=1)\n",
    "data3 = pd.get_dummies(data3,drop_first=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to use drop first because the third option of reward is given already when the other 2 are 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now put everything back together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = pd.concat([data2,data3],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary functions for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_display_results(model,predic,X_test,y_test):\n",
    "    # accuracy_score\n",
    "    # fitted X_test data vs. y_test data (actual answer)\n",
    "    accuracy =   round(accuracy_score(predic,y_test),2)\n",
    "    # Kappa score\n",
    "    kappa =  round(cohen_kappa_score(y_test,predic),2)\n",
    "    # classification report\n",
    "    classif_report = classification_report(predic,y_test)\n",
    "    # compare predictions to actual answers\n",
    "    conf_mat = confusion_matrix(predic,y_test).T\n",
    "    return accuracy, kappa, conf_mat,classif_report\n",
    "\n",
    "def append_to_results(accuracy, kappa, conf_mat,classif_report):\n",
    "    infos_from_model =[]\n",
    "    infos_from_model.append(accuracy)\n",
    "    infos_from_model.append(kappa)\n",
    "    infos_from_model.append(conf_mat)\n",
    "    infos_from_model.append(classif_report)\n",
    "    return infos_from_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Create and 6. Apply different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X-y split\n",
    "X = data4.drop(['offer_accepted'], axis=1)\n",
    "y = data4['offer_accepted']\n",
    "y.columns = ['offer_accepted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will store the values of the results of the different models in a dictionary, \n",
    "# so that we can compare them afterwards.\n",
    "results ={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixing the dependend feature imbalance through Smote\n",
    "\n",
    "We will use the Smote method to oversample the \"offer accepted\" feature to fix the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_sm, y_sm = smote.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier().fit(X_train, y_train)\n",
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate results\n",
    "accuracy, kappa, conf_mat,classif_report = calculate_display_results(rfc,predictions,X_test,y_test)\n",
    "# Add results to result dictionary\n",
    "inf_from_model = append_to_results(accuracy, kappa, conf_mat,classif_report)\n",
    "\n",
    "results['rfc']= inf_from_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc 0.93 0.86\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rfc</th>\n",
       "      <td>0.93</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "parameters  Accuracy  Kappa\n",
       "rfc             0.93   0.86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = pd.DataFrame()\n",
    "results_df['parameters']=['Accuracy','Kappa']\n",
    "for key, value in results.items() :\n",
    "    print (key, value[0],value[1])\n",
    "    results_df[key]=[value[0],value[1]]\n",
    "results_df.set_index('parameters',inplace=True)\n",
    "results_df=results_df.T\n",
    "results_df.sort_values(by =['Accuracy', 'Kappa'],inplace=True)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
